{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "UxHGsxOGo5uO",
      "metadata": {
        "id": "UxHGsxOGo5uO"
      },
      "source": [
        "# Introduction to Neural Networks: SVHN Digit Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AIZ-vu3yo-FI",
      "metadata": {
        "id": "AIZ-vu3yo-FI"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5AsuwpE9pA5M",
      "metadata": {
        "id": "5AsuwpE9pA5M"
      },
      "source": [
        "### Context"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fDTtpCLapEg6",
      "metadata": {
        "id": "fDTtpCLapEg6"
      },
      "source": [
        "The ability to process visual information using machine learning algorithms can be very useful as demonstrated in various applications. The Street View House Numbers (SVHN) dataset is one of the most popular ones. It has been used in neural networks created by Google to read house numbers and match them to their geolocations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6o00avHGpTRP",
      "metadata": {
        "id": "6o00avHGpTRP"
      },
      "source": [
        "### Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RhWhowjxpcep",
      "metadata": {
        "id": "RhWhowjxpcep"
      },
      "source": [
        "To build a model that can identify house numbers in an image."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2AkCH9A-ps6G",
      "metadata": {
        "id": "2AkCH9A-ps6G"
      },
      "source": [
        "### Data Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yMkr1n--ptrd",
      "metadata": {
        "id": "yMkr1n--ptrd"
      },
      "source": [
        "- Number of classes: 10\n",
        "- Training data: 42000 images\n",
        "- Testing data: 18000 images"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jLLNMquHp33t",
      "metadata": {
        "id": "jLLNMquHp33t"
      },
      "source": [
        "## **Please read the instructions carefully before starting the project.**\n",
        "\n",
        "This is a commented Python Notebook file in which all the instructions and tasks to be performed are mentioned.\n",
        "\n",
        "* Blanks '_______' are provided in the notebook that need to be filled with an appropriate code to get the correct result\n",
        "\n",
        "* With every '_______' blank, there is a comment that briefly describes what needs to be filled in the blank space\n",
        "\n",
        "* Identify the task to be performed correctly and only then proceed to write the required code\n",
        "\n",
        "* Fill the code wherever asked by the commented lines like \"# write your code here\" or \"# complete the code\"\n",
        "\n",
        "* Running incomplete code may throw an error\n",
        "\n",
        "* Please run the codes in a sequential manner from the beginning to avoid any unnecessary errors\n",
        "\n",
        "* Add the results/observations derived from the analysis in the presentation and submit the same in .pdf format"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "P3WVDCveqCI_",
      "metadata": {
        "id": "P3WVDCveqCI_"
      },
      "source": [
        "## Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0dd764d6",
      "metadata": {
        "id": "0dd764d6"
      },
      "outputs": [],
      "source": [
        "# Libraries to help with reading and manipulating data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Library to split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Library to encode the variables\n",
        "from sklearn import preprocessing\n",
        "# To plot confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# libaries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# library to import to standardize the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#To import different metrics\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras import backend\n",
        "# importing different functions to build models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import tensorflow as tf\n",
        "import random\n",
        "#Importing classback API\n",
        "from keras import callbacks\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import losses\n",
        "\n",
        "# Library to avoid the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dVdEmlfZ1U33"
      },
      "id": "dVdEmlfZ1U33",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e2a212a",
      "metadata": {
        "id": "8e2a212a"
      },
      "outputs": [],
      "source": [
        "!unzip 'Train.zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 'Test.zip'"
      ],
      "metadata": {
        "id": "0p7IY4D-AsEB"
      },
      "id": "0p7IY4D-AsEB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9aGYbt60qqF5",
      "metadata": {
        "id": "9aGYbt60qqF5"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6a9fad6d",
      "metadata": {
        "id": "6a9fad6d"
      },
      "outputs": [],
      "source": [
        "## Reading the dataset\n",
        "X_test = pd.read_csv(\"X_test.csv\")\n",
        "X_train = pd.read_csv(\"X_train.csv\")\n",
        "y_test = pd.read_csv(\"y_test.csv\")\n",
        "y_train = pd.read_csv(\"y_train.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99sXlMY7JvGG",
      "metadata": {
        "id": "99sXlMY7JvGG"
      },
      "source": [
        "**NOTE**: Since the data shared is in X_train, X_test, y_train, and y_test, there is no need to split the data further."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i_Ut2OoorHiB",
      "metadata": {
        "id": "i_Ut2OoorHiB"
      },
      "source": [
        "## Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2a320a4e",
      "metadata": {
        "id": "2a320a4e"
      },
      "outputs": [],
      "source": [
        "# normalize inputs from 0-255 to 0-1; to be used with the NN\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test/255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Tsgc-YgwrWpj",
      "metadata": {
        "id": "Tsgc-YgwrWpj"
      },
      "source": [
        "## Encode the target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3060c6cc",
      "metadata": {
        "id": "3060c6cc"
      },
      "outputs": [],
      "source": [
        "# Encode the target variable\n",
        "y_train_en = to_categorical(y_train)\n",
        "y_test_en = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_KTDzdHkjQ7W",
      "metadata": {
        "id": "_KTDzdHkjQ7W"
      },
      "source": [
        "## Model Building: Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dFWOvP7eX6kZ",
      "metadata": {
        "id": "dFWOvP7eX6kZ"
      },
      "outputs": [],
      "source": [
        "def make_confusion_matrix(cf,\n",
        "                          group_names=None,\n",
        "                          categories='auto',\n",
        "                          count=True,\n",
        "                          percent=True,\n",
        "                          cbar=True,\n",
        "                          xyticks=True,\n",
        "                          xyplotlabels=True,\n",
        "                          sum_stats=True,\n",
        "                          figsize=(20, 15),\n",
        "                          cmap='Blues',\n",
        "                          title=None):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    '''\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==2:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
        "                accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)\n",
        "\n",
        "    if title:\n",
        "        plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i5XOvFK_jQEz",
      "metadata": {
        "id": "i5XOvFK_jQEz"
      },
      "outputs": [],
      "source": [
        "backend.clear_session()\n",
        "#Fixing the seed for random number generators so that we can ensure we receive the same output everytime\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Fx67v9fdjUmA",
      "metadata": {
        "id": "Fx67v9fdjUmA"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "# Complete the code to add the input layer with 256 neurons with relu as activation function with input of 1024 variables\n",
        "model.add(Dense(___, activation='____',kernel_initializer='he_uniform',input_shape=(1024,)))\n",
        "# Complete the code to add the hidden layer with 64 neurons with relu as activation function\n",
        "model.add(Dense(____, activation='____',kernel_initializer='he_uniform'))\n",
        "# Complete the code to add the hidden layer with 64 neurons with relu as activation function\n",
        "model.add(Dense(____, activation='____',kernel_initializer='he_uniform'))\n",
        "# Complete the code to add the hidden layer with 64 neurons with relu as activation function\n",
        "model.add(Dense(____, activation='___',kernel_initializer='he_uniform'))\n",
        "# Complete the code to add the output layer with softmax as activation function with 10 neurons (We are predicting 10 classes)\n",
        "model.add(Dense(____, activation='_____'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oYc0my5Pkt7w",
      "metadata": {
        "id": "oYc0my5Pkt7w"
      },
      "outputs": [],
      "source": [
        "## Complete the code to compile the model with Adam optimizer and categorical cross entropy as loss with accuracy as metrics\n",
        "model.compile(optimizer='_____', loss='_____', metrics=['_____'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "obqvkfGFlAJk",
      "metadata": {
        "id": "obqvkfGFlAJk"
      },
      "outputs": [],
      "source": [
        "## Complete the code to obtain the summary of the model\n",
        "_____.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e_vF1V_6lIRC",
      "metadata": {
        "id": "e_vF1V_6lIRC"
      },
      "outputs": [],
      "source": [
        "## Complete the code to fit the model on X_train and y_train_en data for 100 epochs\n",
        "history=model.fit(____, ____, validation_split=0.2, epochs='____', batch_size=128, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Cb0jtyx6l0zz",
      "metadata": {
        "id": "Cb0jtyx6l0zz"
      },
      "source": [
        "**Loss function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sutXFAUhl2Um",
      "metadata": {
        "id": "sutXFAUhl2Um"
      },
      "outputs": [],
      "source": [
        "# Capturing learning history per epoch\n",
        "hist  = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "\n",
        "# Plotting accuracy at different epochs\n",
        "plt.plot(hist['loss'])\n",
        "plt.plot(hist['val_loss'])\n",
        "plt.legend((\"train\" , \"valid\") , loc =0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9WFdRPbVOgaw",
      "metadata": {
        "id": "9WFdRPbVOgaw"
      },
      "outputs": [],
      "source": [
        "## Complete the code to predict the model on X_test data\n",
        "y_pred1=model.predict('_____')\n",
        "\n",
        "#Let's predict using argmax\n",
        "y_pred_arg=np.argmax(y_pred1,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m4t50nk4RUAi",
      "metadata": {
        "id": "m4t50nk4RUAi"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5sVrlaB2RvMT",
      "metadata": {
        "id": "5sVrlaB2RvMT"
      },
      "outputs": [],
      "source": [
        "## To get the classification report\n",
        "cr=metrics.classification_report(y_test,y_pred_arg)\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tD2ZdA2kRqw9",
      "metadata": {
        "id": "tD2ZdA2kRqw9"
      },
      "source": [
        "**Classification Report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ry9Hvy4QOg9m",
      "metadata": {
        "id": "Ry9Hvy4QOg9m"
      },
      "outputs": [],
      "source": [
        "## Plot the confusion matrix\n",
        "cm2 = confusion_matrix(y_test, y_pred_arg)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "make_confusion_matrix(cm2, cmap='Blues')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_8pwEMqKOiny",
      "metadata": {
        "id": "_8pwEMqKOiny"
      },
      "source": [
        "## Model Improvement: Neural Network model with Adam Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZR9BU1YbOlMF",
      "metadata": {
        "id": "ZR9BU1YbOlMF"
      },
      "outputs": [],
      "source": [
        "backend.clear_session()\n",
        "#Fixing the seed for random number generators so that we can ensure we receive the same output everytime\n",
        "np.random.seed(2)\n",
        "random.seed(2)\n",
        "tf.random.set_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2IaxKJZgOnxv",
      "metadata": {
        "id": "2IaxKJZgOnxv"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "      ## Initializing the neural network\n",
        "      model = Sequential()\n",
        "\n",
        "      ## Complete the code to add the input layer with 64 neurons and relu as activation function\n",
        "      model.add(Dense(____,activation='____',input_dim = X_train.shape[1]))\n",
        "\n",
        "      ## Complete the code to add the first hidden layer with 32 neurons with relu as activation functions\n",
        "      model.add(Dense(_____,activation='____'))\n",
        "\n",
        "      ## Complete the code to add the output layer with softmax as activation function with 10 neurons (We are predicting 10 classes)\n",
        "      model.add(Dense(____, activation = '____'))\n",
        "\n",
        "\n",
        "      optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "\n",
        "      ## Complete the code to compile the model with binary cross entropy as loss function and accuracy as metrics\n",
        "      model.compile(loss=losses.categorical_crossentropy,optimizer=optimizer,metrics=['accuracy'])\n",
        "      return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p_xSqTwGOpRT",
      "metadata": {
        "id": "p_xSqTwGOpRT"
      },
      "outputs": [],
      "source": [
        "# Initializing the above function\n",
        "model_2=create_model()\n",
        "## Complete the code to get the model summary\n",
        "______.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rQUE9NY-OrDm",
      "metadata": {
        "id": "rQUE9NY-OrDm"
      },
      "outputs": [],
      "source": [
        "## Complete the code to fit the model on X_train and y_train_en data for 100 epochs\n",
        "history_2=model_2.fit(______, ______, validation_split=0.2, epochs=____, batch_size=128, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0PKcTQSwOriW",
      "metadata": {
        "id": "0PKcTQSwOriW"
      },
      "source": [
        "**Loss function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3Q1Vae8_OtCZ",
      "metadata": {
        "id": "3Q1Vae8_OtCZ"
      },
      "outputs": [],
      "source": [
        "# Capturing learning history per epoch\n",
        "hist  = pd.DataFrame(history_2.history)\n",
        "hist['epoch'] = history_2.epoch\n",
        "\n",
        "# Plotting accuracy at different epochs\n",
        "plt.plot(hist['loss'])\n",
        "plt.plot(hist['val_loss'])\n",
        "plt.legend((\"train\" , \"valid\") , loc =0)\n",
        "\n",
        "## Complete the code to evaluate the model on X_test and y_test\n",
        "results = model_2.evaluate(X_test, y_test_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Pyf6HHjITw_y",
      "metadata": {
        "id": "Pyf6HHjITw_y"
      },
      "outputs": [],
      "source": [
        "## Complete the code to predict the model on X_test\n",
        "y_pred2=model_2.predict(______)\n",
        "\n",
        "## Complete the code to the y_pred2 predict using argmax\n",
        "y_pred_arg_2=np.argmax(___,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EfZmpwhGT9RC",
      "metadata": {
        "id": "EfZmpwhGT9RC"
      },
      "source": [
        "**Classification report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fLQSiVJLT-vk",
      "metadata": {
        "id": "fLQSiVJLT-vk"
      },
      "outputs": [],
      "source": [
        "## Complete the code to get the classification report on y_test and y_pred_arg_2\n",
        "cr=metrics.classification_report(_____,_______)\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sZ4SPQTmULn-",
      "metadata": {
        "id": "sZ4SPQTmULn-"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iSOkucJqUMAA",
      "metadata": {
        "id": "iSOkucJqUMAA"
      },
      "outputs": [],
      "source": [
        "## Complete the code to get the classification report on y_test and y_pred_arg_2\n",
        "cm2 = confusion_matrix(_____, ______)\n",
        "\n",
        "## Complete the code to get the confusion matrix\n",
        "make_confusion_matrix(_____, cmap='Blues')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ooAE8N2KUdxg",
      "metadata": {
        "id": "ooAE8N2KUdxg"
      },
      "source": [
        "## Model Improvement: Neural Network model with Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2U33l3XWUeGv",
      "metadata": {
        "id": "2U33l3XWUeGv"
      },
      "outputs": [],
      "source": [
        "backend.clear_session()\n",
        "#Fixing the seed for random number generators so that we can ensure we receive the same output everytime\n",
        "np.random.seed(2)\n",
        "random.seed(2)\n",
        "tf.random.set_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JpOvLAm5UhDH",
      "metadata": {
        "id": "JpOvLAm5UhDH"
      },
      "outputs": [],
      "source": [
        "#Initializing the neural network\n",
        "model_3 = Sequential()\n",
        "\n",
        "## Complete the code to add the input layer with 32 neurons and relu as activation function\n",
        "model_3.add(Dense(____,activation='______',input_dim = X_train.shape[1]))\n",
        "\n",
        "## Complete the code to add dropout with dropout_rate= 0.2\n",
        "model_3.add(Dropout(____))\n",
        "\n",
        "## Complete the code to add the hiden layer with 32 neurons and relu as activation function\n",
        "model_3.add(Dense(____,activation='___'))\n",
        "\n",
        "## Complete the code to add dropout with dropout_rate= 0.1\n",
        "model_3.add(Dropout(____))\n",
        "\n",
        "## Complete the code to add the hiden layer with 8 neurons and relu as activation functio\n",
        "model_3.add(Dense(____,activation='_____'))\n",
        "\n",
        "## Complete the code to add the output layer with softmax as activation function with 10 neurons (We are predicting 10 classes)\n",
        "model_3.add(Dense(10, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h9pWtzByU6UL",
      "metadata": {
        "id": "h9pWtzByU6UL"
      },
      "outputs": [],
      "source": [
        "## Complete the code to get the summary of the model_3\n",
        "______.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WnhDp5o3U_-p",
      "metadata": {
        "id": "WnhDp5o3U_-p"
      },
      "outputs": [],
      "source": [
        "# Initialize the ANN with Adam optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "\n",
        "## Complete the code to compile the model with categorical cross entropy as loss function and accuracy as metrics\n",
        "model_3.compile(loss='_______',optimizer=optimizer,metrics=['_______'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t0lGwfQoVIF3",
      "metadata": {
        "id": "t0lGwfQoVIF3"
      },
      "outputs": [],
      "source": [
        "## Complete the code to fit the model on X_train and y_train_en with 100 epochs\n",
        "history_3 = model_3.fit(_____,______,batch_size=32,epochs=_____,verbose=1,validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3VA3Z6aPVUxt",
      "metadata": {
        "id": "3VA3Z6aPVUxt"
      },
      "source": [
        "**Loss function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FDM2vr7jVTah",
      "metadata": {
        "id": "FDM2vr7jVTah"
      },
      "outputs": [],
      "source": [
        "# Capturing learning history per epoch\n",
        "hist  = pd.DataFrame(history_3.history)\n",
        "hist['epoch'] = history_3.epoch\n",
        "\n",
        "# Plotting accuracy at different epochs\n",
        "plt.plot(hist['loss'])\n",
        "plt.plot(hist['val_loss'])\n",
        "plt.legend((\"train\" , \"valid\") , loc =0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JOnJPfL3VT8z",
      "metadata": {
        "id": "JOnJPfL3VT8z"
      },
      "outputs": [],
      "source": [
        "## Complete the code to predict the model on X_test\n",
        "y_pred3=model_3.predict(X_test)\n",
        "\n",
        "## Complete the code to the y_pred3 predict using argmax\n",
        "y_pred_arg_3=np.argmax(y_pred3,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ppF02vWcVd69",
      "metadata": {
        "id": "ppF02vWcVd69"
      },
      "source": [
        "**Classification report**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ixYZjZWkVf0f",
      "metadata": {
        "id": "ixYZjZWkVf0f"
      },
      "outputs": [],
      "source": [
        "## Complete the code to get the classification report on y_test and y_pred_arg_3\n",
        "cr=metrics.classification_report(_____,_______)\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "t_JPGn2cVn_w",
      "metadata": {
        "id": "t_JPGn2cVn_w"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FZv1Y1rZVpyO",
      "metadata": {
        "id": "FZv1Y1rZVpyO"
      },
      "outputs": [],
      "source": [
        "## Complete the code to get the classification report on y_test and y_pred_arg_3\n",
        "cm2 = confusion_matrix(_____, ______)\n",
        "\n",
        "## Complete the code to get the confusion matrix\n",
        "make_confusion_matrix(_____, cmap='Blues')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3FEEllXeYkdB",
      "metadata": {
        "id": "3FEEllXeYkdB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "A9c1HvoIglo_",
      "metadata": {
        "id": "A9c1HvoIglo_"
      },
      "source": [
        "## Final Model selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7JeYVi68gmpW",
      "metadata": {
        "id": "7JeYVi68gmpW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "gW3JQVN9Yll1",
      "metadata": {
        "id": "gW3JQVN9Yll1"
      },
      "source": [
        "## Insights and Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "skOwmYltYnnq",
      "metadata": {
        "id": "skOwmYltYnnq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "_ummuVUKaDsl",
      "metadata": {
        "id": "_ummuVUKaDsl"
      },
      "source": [
        "---------------"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "AIZ-vu3yo-FI",
        "5AsuwpE9pA5M",
        "6o00avHGpTRP",
        "2AkCH9A-ps6G",
        "9aGYbt60qqF5",
        "i_Ut2OoorHiB",
        "Tsgc-YgwrWpj",
        "_KTDzdHkjQ7W",
        "_8pwEMqKOiny",
        "ooAE8N2KUdxg",
        "A9c1HvoIglo_",
        "gW3JQVN9Yll1"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}